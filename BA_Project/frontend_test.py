# frontend.py
import time, re, os
import pandas as pd
from typing import Tuple, List
import streamlit as st
from backend_test import get_raw_df, get_pivot_df, get_fact_numbers, get_days_raw_df, prepare_weekday_comparison, get_weekday_diff_summary
from dotenv import load_dotenv
from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline
from langchain_core.messages import HumanMessage
from transformers import BitsAndBytesConfig

# ----------------------------
# ëª¨ë¸ ì´ˆê¸°í™” (ìµœì´ˆ 1íšŒ ì‹¤í–‰)
# ----------------------------
@st.cache_resource
def load_llm():
    load_dotenv()
    hf_token = os.getenv("HF_TOKEN")
    
    quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype="float16",
    bnb_4bit_use_double_quant=True,
    )
    
    chat_model = HuggingFacePipeline.from_model_id(
        model_id='LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct',
        task='text-generation',
        device_map="auto",
        pipeline_kwargs=dict(
            max_new_tokens=3000,
            do_sample=False,
            repetition_penalty=1.03
        ),
        model_kwargs={'quantization_config': quantization_config,'trust_remote_code': True}
    )
    llm = ChatHuggingFace(llm=chat_model)
    return llm

llm = load_llm()


# @st.cache_data
raw_df = get_raw_df()
raw_day_df = get_days_raw_df()
pivot_df = get_pivot_df(raw_df)

def extract_week(text):
    match = re.search(r"(20\d{2}-W\d{2})(?!\d)", text)
    return match.group(1) if match else None


# Streamlit UI
st.title("ğŸ“Š Weekly Market Share ìš”ì•½ ì±—ë´‡")
st.markdown("ì£¼ê°„ ê¸°ì¤€ KPIë¥¼ ìš”ì•½í•˜ê³  ì‹¶ì€ ì£¼ì°¨ë¥¼ í¬í•¨í•œ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []  # [(ì§ˆë¬¸, ì‘ë‹µ)]
if "last_kpi_week" not in st.session_state:
    st.session_state.last_kpi_week = None

# ì´ì „ íˆìŠ¤í† ë¦¬ì˜ ì¶œë ¥
if st.session_state.chat_history:
    st.markdown("### ğŸ’¬ ì´ì „ ëŒ€í™”")
    for idx, (q, a) in enumerate(st.session_state.chat_history):
        with st.chat_message("user"):
            st.markdown(q)
        with st.chat_message("assistant"):
            st.markdown(a)

user_query = st.text_input("ì§ˆë¬¸ ì…ë ¥", placeholder="ì˜ˆ: 2025-W13 ê¸°ì¤€ KPI ìš”ì•½í•´ì¤˜")

if user_query:
    week = extract_week(user_query)
    if not week:
        if st.session_state.last_kpi_week:
            week = st.session_state.last_kpi_week
        else:
            st.error("ì…ë ¥í•œ ì§ˆë¬¸ì—ì„œ ê¸°ì¤€ ì£¼ì°¨ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ˆ: '2025-W13'")
            st.stop()

    try:
        (latest, fact_list) = get_fact_numbers(pivot_df, week)
        fact_b, fact_c, fact_y = fact_list[0], fact_list[1], fact_list[2]
        total_cnt = latest["CNT_TOTAL"]

        # ìš”ì¼ë³„ KPI ë¹„êµ ìš”ì•½
        weekday_comp = prepare_weekday_comparison(raw_day_df, week)
        weekday_summary = get_weekday_diff_summary(weekday_comp, week)

        prev_answer = st.session_state.chat_history[-1][1] if st.session_state.chat_history else ""

        prompt = f"""
        [ì—…ë¬´ ëª©ì ] ë‹¹ì‹ ì€ Yì‚¬ì˜ ìœ ëŠ¥í•œ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤.
        ë‹¤ìŒì€ ê° ë°°ë‹¬ í”Œë«í¼ 3ì‚¬ì˜ ì£¼ê°„ KPI ìˆ˜ì¹˜ì…ë‹ˆë‹¤.
        3ê°œ ê¸°ì—… ë³„ë¡œ ê°ê° ì „ì£¼ ëŒ€ë¹„ ë§¤ì¶œ, ì£¼ë¬¸ìˆ˜, ì ìœ ìœ¨ì˜ ë³€ë™ì„ ê³„ì‚°í•˜ê³  ìš”ì•½í•´ì£¼ì„¸ìš”. 
        ë˜í•œ 3ê°œ ê¸°ì—… ë³„ë¡œ ì›”ìš”ì¼ë¶€í„° ì¼ìš”ì¼ê¹Œì§€ì˜ ì ìœ ìœ¨ íë¦„ì„ ë¶„ì„í•˜ê³  ì „ì£¼ì™€ì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•´ ìš”ì•½í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.
        
        [ì§€ì‹œì‚¬í•­]
        ì•„ë˜ ì£¼ê°„ ìš”ì•½ ë° ìš”ì¼ë³„ í‘œëŠ” ë¶„ì„ì„ ìœ„í•œ ì°¸ê³ ìš© ë°ì´í„°ì…ë‹ˆë‹¤.
        í‘œë¥¼ ê·¸ëŒ€ë¡œ ë‚˜ì—´í•˜ê±°ë‚˜ ë³µì‚¬í•˜ì§€ ë§ê³  ë‹µë³€ì€ ë°˜ë“œì‹œ ë‹¹ì‹ ì´ ì§ì ‘ ë°ì´í„°ë¥¼ ë¶„ì„í•œ ê²ƒì²˜ëŸ¼ ìš”ì•½/ì •ë¦¬í•´ì£¼ì„¸ìš”.
        ìš”ì¼ë³„ ë¶„ì„ì‹œ ëª¨ë“  ìš”ì¼ì— ëŒ€í•´ ì „ì£¼ ëŒ€ë¹„ ì¦ê°ì˜ ì •ë„ì™€ ì¶”ì„¸ ë“±ì˜ ì •ë³´ë¥¼ ìš”ì•½í•´ì•¼í•©ë‹ˆë‹¤.
        
        [ì‘ë‹µ í˜•ì‹ ì§€ì¹¨]
        - ì „ì²´ ì‘ë‹µì€ 5~7ê°œì˜ ë‹¨ë½ìœ¼ë¡œ ìš”ì•½í•˜ê³  ìš”ì ì„ ì •ë¦¬í•´ì£¼ì„¸ìš”.
        - ì ìœ ìœ¨ì˜ ë³€ë™ì€ í¼ì„¼íŠ¸(%)ì™€ í¼ì„¼íŠ¸ í¬ì¸íŠ¸(%p) ëª¨ë‘ ê³„ì‚°í•´ì•¼ í•©ë‹ˆë‹¤.
        - ì£¼ìš” í¬ì¸íŠ¸ë¥¼ ìš”ì•½í•  ë•Œ ë°˜ë“œì‹œ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë¥¼ í•¨ê»˜ ê¸°ì…í•´ì•¼ í•©ë‹ˆë‹¤.
        - ê³„ì‚° ê³¼ì •ì€ ìƒëµí•´ì£¼ì„¸ìš”.
        - íŠ¹íˆ ì ìœ ìœ¨ì˜ ë³€í™”ë‚˜ ê²½ìŸì‚¬ì™€ì˜ ê²©ì°¨ í™•ëŒ€ ë“±ì— ì£¼ëª©í•´ ì£¼ì„¸ìš”.
        - ë§ˆì§€ë§‰ ìš”ì•½ ì‹œ ê¸°ì—…ì— ëŒ€í•œ ì¢…í•©ì ì¸ í‰ê°€ëŠ” ìƒëµí•´ì£¼ì„¸ìš”.
        
        [ì´ì „ ìš”ì•½]
        {prev_answer}

        [ì£¼ê°„ KPI ìˆ˜ì¹˜ ìš”ì•½ - {latest['base_week']} ê¸°ì¤€]
        {fact_b}
        {fact_c}
        {fact_y}
        ì „ì²´ ì£¼ë¬¸ìˆ˜: {total_cnt:,}ê±´

        [ìš”ì¼ë³„ KPI ë¹„êµ ìš”ì•½]
        ë‹¤ìŒì€ ê° ê¸°ì—…ë³„ë¡œ ì´ë²ˆ ì£¼ ì›”ìš”ì¼ë¶€í„° ì¼ìš”ì¼ê¹Œì§€ì˜ GMV ë° ì£¼ë¬¸ìˆ˜ ì ìœ ìœ¨(%)ê³¼, ì§€ë‚œ ì£¼ ëŒ€ë¹„ ì ìœ ìœ¨ ë³€í™”(%p)ë¥¼ ìš”ì•½í•œ í‘œì…ë‹ˆë‹¤.
        
        {weekday_summary}
        
        [ì§ˆë¬¸]
        {user_query}
        """.strip()

        with st.spinner("ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤..."):
            response = llm.invoke([HumanMessage(content=prompt)])
            raw_text = response.content.strip()

            if "[|assistant|]" in raw_text:
                answer = raw_text.split("[|assistant|]", 1)[-1].strip()
            else:
                answer = raw_text

            # í˜„ì¬ ì§ˆë¬¸/ì‘ë‹µë„ í™”ë©´ì— ì¶”ê°€ ì¶œë ¥
            with st.chat_message("user"):
                st.markdown(user_query)
            with st.chat_message("assistant"):
                placeholder = st.empty()
                typed_text = ""
                for char in answer:
                    typed_text += char
                    placeholder.markdown(typed_text)
                    time.sleep(0.01)

            # ì„¸ì…˜ ìƒíƒœì— ê¸°ë¡
            st.session_state.chat_history.append((user_query, answer))
            st.session_state.last_kpi_week = week

    except Exception as e:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")